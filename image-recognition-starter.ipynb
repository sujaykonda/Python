{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Image Recognition\n",
    "===\n",
    "\n",
    "This notebook will create a convolutional neural network to classify images in either the mnist or cifar-10 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow and numpy to create the neural network\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib to plot info to show our results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OS to load files and save checkpoints\n",
    "import os\n",
    "\n",
    "from tensorflow.python.keras.datasets import fashion_mnist\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data\n",
    "---\n",
    "\n",
    "This code will load the dataset that you'll use to train and test the model.\n",
    "\n",
    "The code provided will load the mnist or cifar data from files, you'll need to add the code that processes it into a format your neural network can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST\n",
    "---\n",
    "\n",
    "Run this cell to load mnist data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image_height = 28\\nimage_width = 28\\n\\ncolor_channels = 1\\n\\nmodel_name = \"mnist\"\\n\\nmnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\\n\\ntrain_data = mnist.train.images\\ntrain_labels = np.asarray(mnist.train.labels, dtype=np.int32)\\n\\neval_data = mnist.test.images\\neval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\\n\\ncategory_names = list(map(str, range(10)))\\n\\n# TODO: Process mnist data\\ntrain_data = np.reshape(train_data, (-1, image_height, image_width, color_channels))\\n\\nprint(train_data.shape)\\n\\neval_data = np.reshape(eval_data, (-1, image_height, image_width, color_channels))'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST data from tf examples\n",
    "\n",
    "'''image_height = 28\n",
    "image_width = 28\n",
    "\n",
    "color_channels = 1\n",
    "\n",
    "model_name = \"mnist\"\n",
    "\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "\n",
    "train_data = mnist.train.images\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "\n",
    "eval_data = mnist.test.images\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "category_names = list(map(str, range(10)))\n",
    "\n",
    "# TODO: Process mnist data\n",
    "train_data = np.reshape(train_data, (-1, image_height, image_width, color_channels))\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "eval_data = np.reshape(eval_data, (-1, image_height, image_width, color_channels))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 28\n",
    "image_width = 28\n",
    "\n",
    "color_channels = 1\n",
    "model_name = \"mnist_fashion\"\n",
    "\n",
    "((train_data, train_labels),(eval_data, eval_labels)) = fashion_mnist.load_data()\n",
    "\n",
    "train_data = np.reshape(train_data, (-1, image_height, image_width, color_channels))\n",
    "\n",
    "eval_data = np.reshape(eval_data, (-1, image_height, image_width, color_channels))\n",
    "\n",
    "train_data = train_data.astype(\"float32\")/255.0\n",
    "\n",
    "eval_data = train_data.astype(\"float32\")/255.0\n",
    "category_name = (\"top\", \"trouser\",\"pullover\", \"dress\", \"coat\", \"sandal\", \"shirt\", \"sneaker\" , \"bag\", \"ankle boot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10\n",
    "---\n",
    "\n",
    "Run this cell to load cifar-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cifar data from file\n",
    "\n",
    "image_height = 32\n",
    "image_width = 32\n",
    "\n",
    "color_channels = 3\n",
    "\n",
    "model_name = \"cifar\"\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "cifar_path = './cifar-10-data/'\n",
    "\n",
    "train_data = np.array([])\n",
    "train_labels = np.array([])\n",
    "\n",
    "# Load all the data batches.\n",
    "for i in range(1,6):\n",
    "    data_batch = unpickle(cifar_path + 'data_batch_' + str(i))\n",
    "    train_data = np.append(train_data, data_batch[b'data'])\n",
    "    train_labels = np.append(train_labels, data_batch[b'labels'])\n",
    "\n",
    "\n",
    "# Load the eval batch.\n",
    "eval_batch = unpickle(cifar_path + 'test_batch')\n",
    "\n",
    "eval_data = eval_batch[b'data']\n",
    "eval_labels = eval_batch[b'labels'] \n",
    "\n",
    "# Load the english category names.\n",
    "category_names_bytes = unpickle(cifar_path + 'batches.meta')[b'label_names']\n",
    "category_names = list(map(lambda x: x.decode(\"utf-8\"), category_names_bytes))\n",
    "\n",
    "# TODO: Process Cifar data\n",
    "def process_data(data): \n",
    "    float_data = np.array(data, dtype=float) / 255.0 \n",
    "    reshaped_data = np.reshape(float_data, (-1, color_channels, image_height, image_width)) \n",
    "    transposed_data = np.transpose(reshaped_data, [0, 2, 3, 1])\n",
    "    return transposed_data\n",
    "\n",
    "train_data = process_data(train_data) \n",
    "eval_data = process_data(eval_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is processed, you have a few variables for the data itself and info about its shape:\n",
    "\n",
    "### Model Info\n",
    "\n",
    "- **image_height, image_width** - The height and width of the processed images\n",
    "- **color_channels** - the number of color channels in the image. This will be either 1 for grayscale or 3 for rgb.\n",
    "- **model_name** - either \"cifar\" or \"mnist\" - if you need to handle anything differently based on the model, check this variable.\n",
    "- **category_names** - strings for each category name (used to print out labels when testing results)\n",
    "\n",
    "### Training Data\n",
    "\n",
    "- **train_data** - the training data images\n",
    "- **train_labels** - the labels for the training data - the \"answer key\"\n",
    "\n",
    "### Evaluation Data\n",
    "\n",
    "- **eval_data** - Image data for evaluation. A different set of images to test your network's effectiveness.\n",
    "- **eval_labels** - the answer key for evaluation data.\n",
    "\n",
    "Building the Neural Network Model\n",
    "--\n",
    "\n",
    "Next, you'll build a neural network with the following architecture:\n",
    "\n",
    "- An input placeholder that takes one or more images.\n",
    "- 1st Convolutional layer with 32 filters and a kernel size of 5x5 and same padding\n",
    "- 1st Pooling layer with a 2x2 pool size and stride of 2\n",
    "- 2nd Convolutional layer with 64 filters and a kernel size of 5x5 and same padding\n",
    "- 2nd Pooling layer with a 2x2 pool size and stride of 2\n",
    "- Flatten the pooling layer\n",
    "- A fully connected layer with 1024 units\n",
    "- A dropout layer with a rate of 0.4\n",
    "- An output layer with an output size equal to the number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: The neural network\n",
    "class ConvNet:\n",
    "    def __init__(self,image_height, image_width, channels, num_classes):\n",
    "        self.input_layer = tf.placeholder(dtype = tf.float32, shape=[None, image_height, image_width, channels], \n",
    "                                          name=\"inputs\") # All of the images\n",
    "        print(self.input_layer.shape)\n",
    "        conv_layer_1 = tf.layers.conv2d(self.input_layer, filters = 32, kernel_size=[6,6], padding=\"same\", \n",
    "                                        activation=tf.nn.relu) # first conv layer\n",
    "        print(conv_layer_1.shape)\n",
    "        \n",
    "        pooling_layer_1 = tf.layers.max_pooling2d(conv_layer_1, pool_size=[3,3], strides=2)  # first pooling layer\n",
    "        print(pooling_layer_1.shape)\n",
    "        \n",
    "        conv_layer_2 = tf.layers.conv2d(pooling_layer_1, filters = 64, kernel_size=[6,6], padding=\"same\", \n",
    "                                        activation=tf.nn.relu)  # Second conv layer\n",
    "        print(conv_layer_2.shape)\n",
    "        \n",
    "        pooling_layer_2 = tf.layers.max_pooling2d(conv_layer_2, pool_size=[3, 3], strides=2) # Second pooling layer\n",
    "        print(pooling_layer_2.shape) \n",
    "        \n",
    "        conv_layer_3 = tf.layers.conv2d(pooling_layer_2, filters = 96, kernel_size=[6,6], padding=\"same\", \n",
    "                                        activation=tf.nn.relu)  # Third conv layer\n",
    "        print(conv_layer_3.shape)\n",
    "        \n",
    "        pooling_layer_3 = tf.layers.max_pooling2d(conv_layer_3, pool_size=[3, 3], strides=2) # Third pooling layer\n",
    "        print(pooling_layer_3.shape) \n",
    "        \n",
    "        flattened_pooling = tf.layers.flatten(pooling_layer_3) # flattening pooling layer so we can get the dense layer\n",
    "        dense_layer = tf.layers.dense(flattened_pooling, 1024, activation=tf.nn.relu)  # densing the layer connencting \n",
    "        print(dense_layer.shape)                                                        #    all the neurons\n",
    "        dropout = tf.layers.dropout(dense_layer, rate=0.1, training = True) # takes a percentage of all the neurons in \n",
    "        outputs = tf.layers.dense(dropout, num_classes)#the weight of each choice     #the input and deactivates them at random\n",
    "        print(outputs.shape)\n",
    "        self.choice = tf.argmax(outputs, axis=1)    #finds best choice and picks\n",
    "        self.probabilities = tf.nn.softmax(outputs) # finds probabilties for what the image might be\n",
    "        self.labels = tf.placeholder(dtype=tf.float32, name=\"labels\") # all of the labels of the pictures\n",
    "        self.accuracy, self.accuracy_op = tf.metrics.accuracy(self.labels, self.choice) # finds accuracy\n",
    "        one_hot_labels = tf.one_hot(indices=tf.cast(self.labels, dtype=tf.int32), depth=num_classes)  #makes it a hot label\n",
    "        self.loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits=outputs) #finds loss\n",
    "        optimizer = tf.train.GradientDescentOptimizer( learning_rate=1e-2) #optimizes\n",
    "        self.train_operation = optimizer.minimize(loss=self.loss, global_step=tf.train.get_global_step()) # minimizes loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Training Process\n",
    "---\n",
    "\n",
    "The cells below will set up and run the training process.\n",
    "\n",
    "- Set up initial values for batch size, training length.\n",
    "- Process data into batched datasets to feed into the network.\n",
    "- Run through batches of training data, update weights, save checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: initialize variables\n",
    "training_steps =20000\n",
    "batch_size = 64\n",
    "path = \"./\" + model_name + \"-cnn/\"\n",
    "load_checkpoint = False\n",
    "performance_graph = np.array([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(?, 32, 32, 3)\n",
      "WARNING:tensorflow:From <ipython-input-5-46b40680c040>:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "(?, 32, 32, 32)\n",
      "WARNING:tensorflow:From <ipython-input-5-46b40680c040>:11: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "(?, 15, 15, 32)\n",
      "(?, 15, 15, 64)\n",
      "(?, 7, 7, 64)\n",
      "(?, 7, 7, 96)\n",
      "(?, 3, 3, 96)\n",
      "WARNING:tensorflow:From <ipython-input-5-46b40680c040>:28: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-46b40680c040>:29: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "(?, 1024)\n",
      "WARNING:tensorflow:From <ipython-input-5-46b40680c040>:31: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "(?, 10)\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d/Conv2D (defined at <ipython-input-5-46b40680c040>:8) ]]\n\nCaused by op 'conv2d/Conv2D', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-4ae015fc6d43>\", line 13, in <module>\n    cnn = ConvNet(image_height,image_width,color_channels,10)\n  File \"<ipython-input-5-46b40680c040>\", line 8, in __init__\n    activation=tf.nn.relu) # first conv layer\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 424, in conv2d\n    return layer.apply(inputs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1227, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1026, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d/Conv2D (defined at <ipython-input-5-46b40680c040>:8) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d/Conv2D}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4ae015fc6d43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mbatch_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# gets the labels of the images out of the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_operation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m            \u001b[1;31m# it runs training, runs finding a accuracy and you feed all the place holders inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d/Conv2D (defined at <ipython-input-5-46b40680c040>:8) ]]\n\nCaused by op 'conv2d/Conv2D', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-4ae015fc6d43>\", line 13, in <module>\n    cnn = ConvNet(image_height,image_width,color_channels,10)\n  File \"<ipython-input-5-46b40680c040>\", line 8, in __init__\n    activation=tf.nn.relu) # first conv layer\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 424, in conv2d\n    return layer.apply(inputs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1227, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1026, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d/Conv2D (defined at <ipython-input-5-46b40680c040>:8) ]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: implement the training loop\n",
    "# TODO: implement the training loop\n",
    "tf.reset_default_graph()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "dataset = dataset.shuffle(buffer_size=train_labels.shape[0])\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat() # shuffles and makes a batch of data\n",
    "\n",
    "dataset_iterator = dataset.make_initializable_iterator()\n",
    "next_element = dataset_iterator.get_next()  # iterates through the training data \n",
    "    \n",
    "cnn = ConvNet(image_height,image_width,color_channels,10)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "                            # it find the folder or creates the folder\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    if load_checkpoint:\n",
    "        checkpoint = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess, checkpoint.model_checkpoint_path) # loads checkpoint\n",
    "    else:                \n",
    "        sess.run(tf.global_variables_initializer()) # if doesn't load checkpoint inits all global variables\n",
    "    \n",
    "    sess.run(tf.local_variables_initializer()) # inits all local variables\n",
    "    sess.run(dataset_iterator.initializer) # init the data iterator\n",
    "    for step in range(training_steps):\n",
    "        current_batch = sess.run(next_element)  # Gets current batch of data\n",
    "        \n",
    "        batch_inputs = current_batch[0] # gets the images out of the data\n",
    "        batch_labels = current_batch[1] # gets the labels of the images out of the data\n",
    "        \n",
    "        sess.run((cnn.train_operation, cnn.accuracy_op), feed_dict={cnn.input_layer:batch_inputs, cnn.labels:batch_labels})\n",
    "           # it runs training, runs finding a accuracy and you feed all the place holders inputs\n",
    "        if step % 10 == 0: \n",
    "             performance_graph=np.append(performance_graph, \n",
    "             sess.run(cnn.accuracy))  # gets the accuracy and adds it to the graph list\n",
    "        if step % 1000 == 0 and step > 0: # print accuracy every 1000 times and saves\n",
    "            current_acc = sess.run(cnn.accuracy)\n",
    "            \n",
    "            print(\"Accuracy at step \" + str(step) + \": \" + str(current_acc))\n",
    "            print(\"Saving checkpoint\")\n",
    "            saver.save(sess, path + model_name, step)\n",
    "        \n",
    "    print(\"Saving final checkpoint for training session.\")\n",
    "    saver.save(sess, path + model_name, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Performance\n",
    "---\n",
    "\n",
    "These cells will evaluate the performance of your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display graph of performance over time\n",
    "\n",
    "plt.figure().set_facecolor('white') \n",
    "plt.xlabel(\"Steps/10\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "plt.plot(performance_graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run through the evaluation data set, check accuracy of model\n",
    "with tf.Session() as sess: \n",
    "        checkpoint = tf.train.get_checkpoint_state(path) \n",
    "        saver.restore(sess, checkpoint.model_checkpoint_path) \n",
    "        sess.run(tf.local_variables_initializer()) \n",
    "        for image, label in zip(eval_data, eval_labels):\n",
    "            sess.run(cnn.accuracy_op, feed_dict={cnn.input_layer:[image], cnn.labels:label}) \n",
    "        print(sess.run(cnn.accuracy)) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Expand this box to check the final code for this cell.\n",
    "# TODO: Get a random set of images and make guesses for each\n",
    "with tf.Session() as sess:\n",
    "    checkpoint = tf.train.get_checkpoint_state(path)\n",
    "    saver.restore(sess,checkpoint.model_checkpoint_path)\n",
    "    \n",
    "    indexes = np.random.choice(len(eval_data), 10, replace=False)\n",
    "    \n",
    "    rows = 5\n",
    "    cols = 2\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5,5))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    image_count = 0\n",
    "    \n",
    "    for idx in indexes:\n",
    "        image_count += 1\n",
    "        sub = plt.subplot(rows,cols,image_count)\n",
    "        img = eval_data[idx]\n",
    "        if model_name == \"mnist\" or model_name == \"mnist_fashion\":\n",
    "            img = img.reshape(28, 28)\n",
    "        plt.imshow(img)\n",
    "        guess = sess.run(cnn.choice, feed_dict={cnn.input_layer:[eval_data[idx]]})\n",
    "        if model_name == \"mnist\" or model_name == \"mnist_fashion\":\n",
    "            guess_name = str(guess[0])\n",
    "            actual_name = str(eval_labels[idx])\n",
    "        else:\n",
    "            guess_name = category_names[guess[0]]\n",
    "            actual_name = category_names[eval_labels[idx]]\n",
    "        sub.set_title(\"G: \" + guess_name + \" A: \" + actual_name)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
